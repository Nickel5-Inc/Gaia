"""initial_validator_schema_separate_config

Revision ID: f75e4f7343a1
Revises:
Create Date: 2025-05-28 15:23:34.145940

"""

from typing import Sequence, Union

import sqlalchemy as sa
from alembic import op
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision: str = "f75e4f7343a1"
down_revision: Union[str, None] = None
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table(
        "baseline_predictions",
        sa.Column(
            "id",
            sa.Integer(),
            autoincrement=True,
            nullable=False,
            comment="Serial ID for the prediction entry",
        ),
        sa.Column(
            "task_name",
            sa.Text(),
            nullable=False,
            comment="Name of the task (e.g., geomagnetic, soil_moisture)",
        ),
        sa.Column(
            "task_id",
            sa.Text(),
            nullable=False,
            comment="ID of the specific task execution",
        ),
        sa.Column(
            "region_id",
            sa.Text(),
            nullable=True,
            comment="For region-specific tasks, the region identifier",
        ),
        sa.Column(
            "timestamp",
            postgresql.TIMESTAMP(timezone=True),
            nullable=False,
            comment="Timestamp for when the prediction was made/is valid for",
        ),
        sa.Column(
            "prediction",
            postgresql.JSONB(astext_type=sa.Text()),
            nullable=False,
            comment="The model's prediction data",
        ),
        sa.Column(
            "created_at",
            postgresql.TIMESTAMP(timezone=True),
            server_default=sa.text("CURRENT_TIMESTAMP"),
            nullable=False,
            comment="Timestamp of prediction storage",
        ),
        sa.PrimaryKeyConstraint("id"),
        comment="Stores baseline model predictions for various tasks.",
    )
    with op.batch_alter_table("baseline_predictions", schema=None) as batch_op:
        batch_op.create_index(
            "idx_baseline_task_on_baseline_predictions",
            ["task_name", "task_id"],
            unique=False,
        )

    op.create_table(
        "geomagnetic_history",
        sa.Column("id", sa.Integer(), autoincrement=True, nullable=False),
        sa.Column("miner_uid", sa.Text(), nullable=False),
        sa.Column("miner_hotkey", sa.Text(), nullable=False),
        sa.Column("query_time", postgresql.TIMESTAMP(timezone=True), nullable=False),
        sa.Column("predicted_value", sa.Float(), nullable=False),
        sa.Column("ground_truth_value", sa.Float(), nullable=False),
        sa.Column("score", sa.Float(), nullable=False),
        sa.Column(
            "scored_at",
            postgresql.TIMESTAMP(timezone=True),
            server_default=sa.text("CURRENT_TIMESTAMP"),
            nullable=False,
        ),
        sa.PrimaryKeyConstraint("id"),
    )
    op.create_table(
        "geomagnetic_predictions",
        sa.Column("id", sa.Text(), nullable=False),
        sa.Column("miner_uid", sa.Text(), nullable=False),
        sa.Column("miner_hotkey", sa.Text(), nullable=False),
        sa.Column("predicted_value", sa.Float(), nullable=False),
        sa.Column(
            "query_time",
            postgresql.TIMESTAMP(timezone=True),
            server_default=sa.text("CURRENT_TIMESTAMP"),
            nullable=False,
        ),
        sa.Column(
            "status", sa.Text(), server_default=sa.text("'pending'"), nullable=False
        ),
        sa.PrimaryKeyConstraint("id"),
    )
    with op.batch_alter_table("geomagnetic_predictions", schema=None) as batch_op:
        batch_op.create_index("idx_gp_miner_hotkey", ["miner_hotkey"], unique=False)
        batch_op.create_index("idx_gp_miner_uid", ["miner_uid"], unique=False)
        batch_op.create_index("idx_gp_query_time", ["query_time"], unique=False)
        batch_op.create_index("idx_gp_status", ["status"], unique=False)

    op.create_table(
        "node_table",
        sa.Column(
            "uid", sa.Integer(), nullable=False, comment="Unique ID for the node, 0-255"
        ),
        sa.Column("hotkey", sa.Text(), nullable=True, comment="Hotkey of the node"),
        sa.Column("coldkey", sa.Text(), nullable=True, comment="Coldkey of the node"),
        sa.Column("ip", sa.Text(), nullable=True, comment="IP address of the node"),
        sa.Column(
            "ip_type",
            sa.Text(),
            nullable=True,
            comment="IP address type (e.g., IPv4, IPv6)",
        ),
        sa.Column(
            "port",
            sa.Integer(),
            nullable=True,
            comment="Port number for the node's services",
        ),
        sa.Column(
            "incentive",
            sa.Float(),
            nullable=True,
            comment="Current incentive score of the node",
        ),
        sa.Column(
            "stake", sa.Float(), nullable=True, comment="Current stake of the node"
        ),
        sa.Column(
            "trust",
            sa.Float(),
            nullable=True,
            comment="Current trust score of the node",
        ),
        sa.Column(
            "vtrust",
            sa.Float(),
            nullable=True,
            comment="Current validator trust score of the node",
        ),
        sa.Column(
            "protocol",
            sa.Text(),
            nullable=True,
            comment="Protocol version used by the node",
        ),
        sa.Column(
            "last_updated",
            postgresql.TIMESTAMP(timezone=True),
            server_default=sa.text("CURRENT_TIMESTAMP"),
            nullable=False,
            comment="Timestamp of the last update for this node's record",
        ),
        sa.CheckConstraint("uid >= 0 AND uid < 256", name="node_table_uid_check"),
        sa.PrimaryKeyConstraint("uid"),
        comment="Table storing information about registered nodes (miners/validators).",
    )
    with op.batch_alter_table("node_table", schema=None) as batch_op:
        batch_op.create_index("idx_node_table_uid", ["uid"], unique=False)
        batch_op.create_index(
            "idx_node_table_uid_last_updated", ["uid", "last_updated"], unique=False
        )

    op.create_table(
        "score_table",
        sa.Column(
            "task_name",
            sa.VARCHAR(length=255),
            nullable=True,
            comment="Name of the task being scored",
        ),
        sa.Column(
            "task_id",
            sa.Text(),
            nullable=True,
            comment="Unique ID for the specific task instance",
        ),
        sa.Column(
            "score",
            postgresql.ARRAY(sa.Float()),
            nullable=True,
            comment="Array of scores, typically per UID",
        ),
        sa.Column(
            "created_at",
            postgresql.TIMESTAMP(timezone=True),
            server_default=sa.text("CURRENT_TIMESTAMP"),
            nullable=False,
            comment="Timestamp of score creation",
        ),
        sa.Column(
            "status",
            sa.VARCHAR(length=50),
            server_default=sa.text("'pending'"),
            nullable=True,
            comment="Status of the scoring process",
        ),
        sa.UniqueConstraint(
            "task_name", "task_id", name="uq_score_table_task_name_task_id"
        ),
        comment="Table to store scores for various tasks.",
    )
    with op.batch_alter_table("score_table", schema=None) as batch_op:
        batch_op.create_index(
            "idx_score_created_at_on_score_table", ["created_at"], unique=False
        )
        batch_op.create_index(
            "idx_score_table_task_name_created_at_desc",
            ["task_name", sa.literal_column("created_at DESC")],
            unique=False,
        )

    op.create_table(
        "soil_moisture_regions",
        sa.Column("id", sa.Integer(), autoincrement=True, nullable=False),
        sa.Column("region_date", sa.Date(), nullable=False),
        sa.Column("target_time", postgresql.TIMESTAMP(timezone=True), nullable=False),
        sa.Column("bbox", postgresql.JSONB(astext_type=sa.Text()), nullable=False),
        sa.Column("combined_data", postgresql.BYTEA(), nullable=True),
        sa.Column("sentinel_bounds", postgresql.ARRAY(sa.Float()), nullable=True),
        sa.Column("sentinel_crs", sa.Integer(), nullable=True),
        sa.Column(
            "status", sa.Text(), server_default=sa.text("'pending'"), nullable=False
        ),
        sa.Column(
            "created_at",
            postgresql.TIMESTAMP(timezone=True),
            server_default=sa.text("CURRENT_TIMESTAMP"),
            nullable=False,
        ),
        sa.Column(
            "data_cleared_at", postgresql.TIMESTAMP(timezone=True), nullable=True
        ),
        sa.Column("array_shape", postgresql.ARRAY(sa.Integer()), nullable=False),
        sa.PrimaryKeyConstraint("id"),
    )
    with op.batch_alter_table("soil_moisture_regions", schema=None) as batch_op:
        batch_op.create_index("idx_smr_region_date", ["region_date"], unique=False)
        batch_op.create_index("idx_smr_status", ["status"], unique=False)
        batch_op.create_index("idx_smr_target_time", ["target_time"], unique=False)

    op.create_table(
        "weather_forecast_runs",
        sa.Column("id", sa.Integer(), autoincrement=True, nullable=False),
        sa.Column(
            "run_initiation_time", postgresql.TIMESTAMP(timezone=True), nullable=False
        ),
        sa.Column(
            "target_forecast_time_utc",
            postgresql.TIMESTAMP(timezone=True),
            nullable=False,
        ),
        sa.Column(
            "gfs_init_time_utc", postgresql.TIMESTAMP(timezone=True), nullable=False
        ),
        sa.Column(
            "gfs_input_metadata", postgresql.JSONB(astext_type=sa.Text()), nullable=True
        ),
        sa.Column(
            "status",
            sa.VARCHAR(length=50),
            server_default=sa.text("'pending'"),
            nullable=False,
        ),
        sa.Column(
            "completion_time", postgresql.TIMESTAMP(timezone=True), nullable=True
        ),
        sa.Column(
            "final_scoring_attempted_time",
            postgresql.TIMESTAMP(timezone=True),
            nullable=True,
        ),
        sa.Column("error_message", sa.Text(), nullable=True),
        sa.PrimaryKeyConstraint("id"),
        comment="Tracks each weather forecast run initiated by the validator.",
    )
    with op.batch_alter_table("weather_forecast_runs", schema=None) as batch_op:
        batch_op.create_index(
            "idx_wfr_gfs_init_time", ["gfs_init_time_utc"], unique=False
        )
        batch_op.create_index(
            "idx_wfr_run_init_time", ["run_initiation_time"], unique=False
        )
        batch_op.create_index("idx_wfr_status", ["status"], unique=False)
        batch_op.create_index(
            "idx_wfr_status_init_time", ["status", "run_initiation_time"], unique=False
        )
        batch_op.create_index(
            "idx_wfr_target_forecast_time", ["target_forecast_time_utc"], unique=False
        )

    op.create_table(
        "soil_moisture_history",
        sa.Column("id", sa.Integer(), autoincrement=True, nullable=False),
        sa.Column("region_id", sa.Integer(), nullable=False),
        sa.Column("miner_uid", sa.Text(), nullable=False),
        sa.Column("miner_hotkey", sa.Text(), nullable=False),
        sa.Column("target_time", postgresql.TIMESTAMP(timezone=True), nullable=False),
        sa.Column(
            "surface_sm_pred", postgresql.ARRAY(sa.Float(), dimensions=2), nullable=True
        ),
        sa.Column(
            "rootzone_sm_pred",
            postgresql.ARRAY(sa.Float(), dimensions=2),
            nullable=True,
        ),
        sa.Column(
            "surface_sm_truth",
            postgresql.ARRAY(sa.Float(), dimensions=2),
            nullable=True,
        ),
        sa.Column(
            "rootzone_sm_truth",
            postgresql.ARRAY(sa.Float(), dimensions=2),
            nullable=True,
        ),
        sa.Column("surface_rmse", sa.Float(), nullable=True),
        sa.Column("rootzone_rmse", sa.Float(), nullable=True),
        sa.Column("surface_structure_score", sa.Float(), nullable=True),
        sa.Column("rootzone_structure_score", sa.Float(), nullable=True),
        sa.Column(
            "scored_at",
            postgresql.TIMESTAMP(timezone=True),
            server_default=sa.text("CURRENT_TIMESTAMP"),
            nullable=False,
        ),
        sa.ForeignKeyConstraint(
            ["region_id"], ["soil_moisture_regions.id"], ondelete="CASCADE"
        ),
        sa.PrimaryKeyConstraint("id"),
    )
    with op.batch_alter_table("soil_moisture_history", schema=None) as batch_op:
        batch_op.create_index("idx_smh_miner_hotkey", ["miner_hotkey"], unique=False)
        batch_op.create_index("idx_smh_miner_uid", ["miner_uid"], unique=False)
        batch_op.create_index("idx_smh_region_id", ["region_id"], unique=False)
        batch_op.create_index("idx_smh_target_time", ["target_time"], unique=False)

    op.create_table(
        "soil_moisture_predictions",
        sa.Column("id", sa.Integer(), autoincrement=True, nullable=False),
        sa.Column("region_id", sa.Integer(), nullable=True),
        sa.Column("miner_uid", sa.Text(), nullable=False),
        sa.Column("miner_hotkey", sa.Text(), nullable=False),
        sa.Column("target_time", postgresql.TIMESTAMP(timezone=True), nullable=False),
        sa.Column(
            "surface_sm", postgresql.ARRAY(sa.Float(), dimensions=2), nullable=True
        ),
        sa.Column(
            "rootzone_sm", postgresql.ARRAY(sa.Float(), dimensions=2), nullable=True
        ),
        sa.Column(
            "uncertainty_surface",
            postgresql.ARRAY(sa.Float(), dimensions=2),
            nullable=True,
        ),
        sa.Column(
            "uncertainty_rootzone",
            postgresql.ARRAY(sa.Float(), dimensions=2),
            nullable=True,
        ),
        sa.Column(
            "created_at",
            postgresql.TIMESTAMP(timezone=True),
            server_default=sa.text("CURRENT_TIMESTAMP"),
            nullable=False,
        ),
        sa.Column("sentinel_bounds", postgresql.ARRAY(sa.Float()), nullable=True),
        sa.Column("sentinel_crs", sa.Integer(), nullable=True),
        sa.Column(
            "status",
            sa.Text(),
            server_default=sa.text("'sent_to_miner'"),
            nullable=False,
        ),
        sa.Column(
            "retry_count", sa.Integer(), server_default=sa.text("0"), nullable=True
        ),
        sa.Column(
            "next_retry_time", postgresql.TIMESTAMP(timezone=True), nullable=True
        ),
        sa.Column("last_error", sa.Text(), nullable=True),
        sa.ForeignKeyConstraint(
            ["region_id"], ["soil_moisture_regions.id"], ondelete="SET NULL"
        ),
        sa.PrimaryKeyConstraint("id"),
    )
    with op.batch_alter_table("soil_moisture_predictions", schema=None) as batch_op:
        batch_op.create_index("idx_smp_miner_hotkey", ["miner_hotkey"], unique=False)
        batch_op.create_index("idx_smp_miner_uid", ["miner_uid"], unique=False)
        batch_op.create_index("idx_smp_region_id", ["region_id"], unique=False)
        batch_op.create_index("idx_smp_status", ["status"], unique=False)
        batch_op.create_index("idx_smp_target_time", ["target_time"], unique=False)

    op.create_table(
        "weather_ensemble_forecasts",
        sa.Column("id", sa.Integer(), autoincrement=True, nullable=False),
        sa.Column("forecast_run_id", sa.Integer(), nullable=False),
        sa.Column(
            "creation_time",
            postgresql.TIMESTAMP(timezone=True),
            server_default=sa.text("CURRENT_TIMESTAMP"),
            nullable=False,
        ),
        sa.Column(
            "processing_end_time", postgresql.TIMESTAMP(timezone=True), nullable=True
        ),
        sa.Column("ensemble_path", sa.Text(), nullable=True),
        sa.Column("ensemble_kerchunk_path", sa.Text(), nullable=True),
        sa.Column("ensemble_verification_hash", sa.VARCHAR(length=64), nullable=True),
        sa.Column(
            "status",
            sa.VARCHAR(length=50),
            server_default=sa.text("'pending'"),
            nullable=False,
        ),
        sa.Column("error_message", sa.Text(), nullable=True),
        sa.ForeignKeyConstraint(
            ["forecast_run_id"], ["weather_forecast_runs.id"], ondelete="CASCADE"
        ),
        sa.PrimaryKeyConstraint("id"),
        comment="Stores ensemble forecast information created by combining multiple miner forecasts.",
    )
    with op.batch_alter_table("weather_ensemble_forecasts", schema=None) as batch_op:
        batch_op.create_index(
            "idx_wef_forecast_run_id", ["forecast_run_id"], unique=False
        )

    op.create_table(
        "weather_historical_weights",
        sa.Column("miner_hotkey", sa.VARCHAR(length=255), nullable=False),
        sa.Column("run_id", sa.Integer(), nullable=False),
        sa.Column("score_type", sa.VARCHAR(length=50), nullable=False),
        sa.Column("score", sa.Float(), nullable=True),
        sa.Column("weight", sa.Float(), nullable=True),
        sa.Column("last_updated", postgresql.TIMESTAMP(timezone=True), nullable=False),
        sa.ForeignKeyConstraint(
            ["run_id"], ["weather_forecast_runs.id"], ondelete="CASCADE"
        ),
        comment="Stores calculated scores and weights for miners on a per-run basis (e.g., initial GFS score).",
    )
    with op.batch_alter_table("weather_historical_weights", schema=None) as batch_op:
        batch_op.create_index("idx_whw_miner_hotkey", ["miner_hotkey"], unique=False)
        batch_op.create_index("idx_whw_run_id", ["run_id"], unique=False)
        batch_op.create_index("idx_whw_score_type", ["score_type"], unique=False)

    op.create_table(
        "weather_miner_responses",
        sa.Column("id", sa.Integer(), autoincrement=True, nullable=False),
        sa.Column("run_id", sa.Integer(), nullable=False),
        sa.Column("miner_uid", sa.Integer(), nullable=False),
        sa.Column("miner_hotkey", sa.VARCHAR(length=255), nullable=False),
        sa.Column("response_time", postgresql.TIMESTAMP(timezone=True), nullable=False),
        sa.Column("job_id", sa.VARCHAR(length=100), nullable=True),
        sa.Column("kerchunk_json_url", sa.Text(), nullable=True),
        sa.Column("target_netcdf_url_template", sa.Text(), nullable=True),
        sa.Column(
            "kerchunk_json_retrieved",
            postgresql.JSONB(astext_type=sa.Text()),
            nullable=True,
        ),
        sa.Column("verification_hash_computed", sa.VARCHAR(length=64), nullable=True),
        sa.Column("verification_hash_claimed", sa.VARCHAR(length=64), nullable=True),
        sa.Column("verification_passed", sa.Boolean(), nullable=True),
        sa.Column(
            "status",
            sa.VARCHAR(length=50),
            server_default=sa.text("'received'"),
            nullable=False,
        ),
        sa.Column("error_message", sa.Text(), nullable=True),
        sa.Column("input_hash_miner", sa.VARCHAR(length=64), nullable=True),
        sa.Column("input_hash_validator", sa.VARCHAR(length=64), nullable=True),
        sa.Column("input_hash_match", sa.Boolean(), nullable=True),
        sa.Column(
            "last_polled_time", postgresql.TIMESTAMP(timezone=True), nullable=True
        ),
        sa.ForeignKeyConstraint(
            ["run_id"], ["weather_forecast_runs.id"], ondelete="CASCADE"
        ),
        sa.PrimaryKeyConstraint("id"),
        sa.UniqueConstraint(
            "run_id", "miner_uid", name="uq_weather_miner_responses_run_miner"
        ),
        comment="Records miner responses for a specific forecast run. Tracks status through fetch, hash verification, and inference.",
    )
    with op.batch_alter_table("weather_miner_responses", schema=None) as batch_op:
        batch_op.create_index("idx_wmr_job_id", ["job_id"], unique=False)
        batch_op.create_index("idx_wmr_miner_hotkey", ["miner_hotkey"], unique=False)
        batch_op.create_index("idx_wmr_miner_uid", ["miner_uid"], unique=False)
        batch_op.create_index("idx_wmr_run_id", ["run_id"], unique=False)
        batch_op.create_index("idx_wmr_status", ["status"], unique=False)
        batch_op.create_index(
            "idx_wmr_verification_passed", ["verification_passed"], unique=False
        )

    op.create_table(
        "weather_ensemble_components",
        sa.Column("id", sa.Integer(), autoincrement=True, nullable=False),
        sa.Column("ensemble_id", sa.Integer(), nullable=False),
        sa.Column("response_id", sa.Integer(), nullable=False),
        sa.Column("weight", sa.Float(), nullable=False),
        sa.Column(
            "created_at",
            postgresql.TIMESTAMP(timezone=True),
            server_default=sa.text("CURRENT_TIMESTAMP"),
            nullable=False,
        ),
        sa.ForeignKeyConstraint(
            ["ensemble_id"], ["weather_ensemble_forecasts.id"], ondelete="CASCADE"
        ),
        sa.ForeignKeyConstraint(
            ["response_id"], ["weather_miner_responses.id"], ondelete="CASCADE"
        ),
        sa.PrimaryKeyConstraint("id"),
        comment="Tracks which miner forecasts are included in an ensemble and their weights.",
    )
    with op.batch_alter_table("weather_ensemble_components", schema=None) as batch_op:
        batch_op.create_index("idx_wec_ensemble_id", ["ensemble_id"], unique=False)
        batch_op.create_index("idx_wec_response_id", ["response_id"], unique=False)

    op.create_table(
        "weather_miner_scores",
        sa.Column("id", sa.Integer(), autoincrement=True, nullable=False),
        sa.Column("response_id", sa.Integer(), nullable=False),
        sa.Column("run_id", sa.Integer(), nullable=False),
        sa.Column("miner_uid", sa.Integer(), nullable=False),
        sa.Column("miner_hotkey", sa.VARCHAR(length=255), nullable=False),
        sa.Column("score_type", sa.VARCHAR(length=50), nullable=False),
        sa.Column(
            "calculation_time", postgresql.TIMESTAMP(timezone=True), nullable=False
        ),
        sa.Column("metrics", postgresql.JSONB(astext_type=sa.Text()), nullable=True),
        sa.Column("score", sa.Float(), nullable=True),
        sa.Column("error_message", sa.Text(), nullable=True),
        sa.Column("lead_hours", sa.Integer(), nullable=True),
        sa.Column("variable_level", sa.String(length=50), nullable=True),
        sa.Column("valid_time_utc", sa.TIMESTAMP(timezone=True), nullable=True),
        sa.ForeignKeyConstraint(
            ["response_id"], ["weather_miner_responses.id"], ondelete="CASCADE"
        ),
        sa.ForeignKeyConstraint(
            ["run_id"], ["weather_forecast_runs.id"], ondelete="CASCADE"
        ),
        sa.PrimaryKeyConstraint("id"),
        sa.UniqueConstraint(
            "response_id",
            "score_type",
            "lead_hours",
            "variable_level",
            "valid_time_utc",
            name="uq_wms_response_scoretype_lead_var_time",
        ),
        comment="Stores calculated scores (e.g., gfs_rmse, era5_rmse) for each miner response, detailed by lead time and variable.",
    )
    with op.batch_alter_table("weather_miner_scores", schema=None) as batch_op:
        batch_op.create_index(
            "idx_wms_calculation_time", ["calculation_time"], unique=False
        )
        batch_op.create_index("idx_wms_lead_hours", ["lead_hours"], unique=False)
        batch_op.create_index("idx_wms_miner_hotkey", ["miner_hotkey"], unique=False)
        batch_op.create_index("idx_wms_miner_uid", ["miner_uid"], unique=False)
        batch_op.create_index("idx_wms_run_id", ["run_id"], unique=False)
        batch_op.create_index("idx_wms_score_type", ["score_type"], unique=False)
        batch_op.create_index(
            "idx_wms_valid_time_utc", ["valid_time_utc"], unique=False
        )
        batch_op.create_index(
            "idx_wms_variable_level", ["variable_level"], unique=False
        )

    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    with op.batch_alter_table("weather_miner_scores", schema=None) as batch_op:
        batch_op.drop_index("idx_wms_variable_level")
        batch_op.drop_index("idx_wms_valid_time_utc")
        batch_op.drop_index("idx_wms_score_type")
        batch_op.drop_index("idx_wms_run_id")
        batch_op.drop_index("idx_wms_miner_uid")
        batch_op.drop_index("idx_wms_miner_hotkey")
        batch_op.drop_index("idx_wms_lead_hours")
        batch_op.drop_index("idx_wms_calculation_time")

    op.drop_table("weather_miner_scores")
    with op.batch_alter_table("weather_ensemble_components", schema=None) as batch_op:
        batch_op.drop_index("idx_wec_response_id")
        batch_op.drop_index("idx_wec_ensemble_id")

    op.drop_table("weather_ensemble_components")
    with op.batch_alter_table("weather_miner_responses", schema=None) as batch_op:
        batch_op.drop_index("idx_wmr_verification_passed")
        batch_op.drop_index("idx_wmr_status")
        batch_op.drop_index("idx_wmr_run_id")
        batch_op.drop_index("idx_wmr_miner_uid")
        batch_op.drop_index("idx_wmr_miner_hotkey")
        batch_op.drop_index("idx_wmr_job_id")

    op.drop_table("weather_miner_responses")
    with op.batch_alter_table("weather_historical_weights", schema=None) as batch_op:
        batch_op.drop_index("idx_whw_score_type")
        batch_op.drop_index("idx_whw_run_id")
        batch_op.drop_index("idx_whw_miner_hotkey")

    op.drop_table("weather_historical_weights")
    with op.batch_alter_table("weather_ensemble_forecasts", schema=None) as batch_op:
        batch_op.drop_index("idx_wef_forecast_run_id")

    op.drop_table("weather_ensemble_forecasts")
    with op.batch_alter_table("soil_moisture_predictions", schema=None) as batch_op:
        batch_op.drop_index("idx_smp_target_time")
        batch_op.drop_index("idx_smp_status")
        batch_op.drop_index("idx_smp_region_id")
        batch_op.drop_index("idx_smp_miner_uid")
        batch_op.drop_index("idx_smp_miner_hotkey")

    op.drop_table("soil_moisture_predictions")
    with op.batch_alter_table("soil_moisture_history", schema=None) as batch_op:
        batch_op.drop_index("idx_smh_target_time")
        batch_op.drop_index("idx_smh_region_id")
        batch_op.drop_index("idx_smh_miner_uid")
        batch_op.drop_index("idx_smh_miner_hotkey")

    op.drop_table("soil_moisture_history")
    with op.batch_alter_table("weather_forecast_runs", schema=None) as batch_op:
        batch_op.drop_index("idx_wfr_target_forecast_time")
        batch_op.drop_index("idx_wfr_status_init_time")
        batch_op.drop_index("idx_wfr_status")
        batch_op.drop_index("idx_wfr_run_init_time")
        batch_op.drop_index("idx_wfr_gfs_init_time")

    op.drop_table("weather_forecast_runs")
    with op.batch_alter_table("soil_moisture_regions", schema=None) as batch_op:
        batch_op.drop_index("idx_smr_target_time")
        batch_op.drop_index("idx_smr_status")
        batch_op.drop_index("idx_smr_region_date")

    op.drop_table("soil_moisture_regions")
    with op.batch_alter_table("score_table", schema=None) as batch_op:
        batch_op.drop_index("idx_score_table_task_name_created_at_desc")
        batch_op.drop_index("idx_score_created_at_on_score_table")

    op.drop_table("score_table")
    with op.batch_alter_table("node_table", schema=None) as batch_op:
        batch_op.drop_index("idx_node_table_uid_last_updated")
        batch_op.drop_index("idx_node_table_uid")

    op.drop_table("node_table")
    with op.batch_alter_table("geomagnetic_predictions", schema=None) as batch_op:
        batch_op.drop_index("idx_gp_status")
        batch_op.drop_index("idx_gp_query_time")
        batch_op.drop_index("idx_gp_miner_uid")
        batch_op.drop_index("idx_gp_miner_hotkey")

    op.drop_table("geomagnetic_predictions")
    op.drop_table("geomagnetic_history")
    with op.batch_alter_table("baseline_predictions", schema=None) as batch_op:
        batch_op.drop_index("idx_baseline_task_on_baseline_predictions")

    op.drop_table("baseline_predictions")
    # ### end Alembic commands ###
