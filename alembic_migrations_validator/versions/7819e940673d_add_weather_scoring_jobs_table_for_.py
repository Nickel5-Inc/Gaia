"""add weather_scoring_jobs table for restart resilience

Revision ID: 7819e940673d
Revises: dc4f1a1ad6db
Create Date: 2025-07-01 21:57:23.355482

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision: str = '7819e940673d'
down_revision: Union[str, None] = 'dc4f1a1ad6db'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('weather_scoring_jobs',
    sa.Column('id', sa.Integer(), autoincrement=True, nullable=False, comment='Serial ID for the scoring job'),
    sa.Column('run_id', sa.Integer(), nullable=False, comment='ID of the forecast run being scored'),
    sa.Column('score_type', sa.VARCHAR(length=50), nullable=False, comment="Type of scoring job (e.g., 'day1_qc', 'era5_final')"),
    sa.Column('status', sa.VARCHAR(length=20), server_default=sa.text("'queued'"), nullable=False, comment='Current status of the scoring job'),
    sa.Column('started_at', postgresql.TIMESTAMP(timezone=True), nullable=True, comment='When the scoring job was started'),
    sa.Column('completed_at', postgresql.TIMESTAMP(timezone=True), nullable=True, comment='When the scoring job was completed'),
    sa.Column('error_message', sa.Text(), nullable=True, comment='Error message if the job failed'),
    sa.Column('created_at', postgresql.TIMESTAMP(timezone=True), server_default=sa.text('CURRENT_TIMESTAMP'), nullable=False, comment='When the scoring job was created'),
    sa.ForeignKeyConstraint(['run_id'], ['weather_forecast_runs.id'], ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id'),
    sa.UniqueConstraint('run_id', 'score_type', name='uq_wsj_run_score_type'),
    comment='Tracks scoring jobs for restart resilience - ensures no scoring work is lost during validator restarts.'
    )
    with op.batch_alter_table('weather_scoring_jobs', schema=None) as batch_op:
        batch_op.create_index('idx_wsj_created_at', ['created_at'], unique=False)
        batch_op.create_index('idx_wsj_run_id', ['run_id'], unique=False)
        batch_op.create_index('idx_wsj_score_type', ['score_type'], unique=False)
        batch_op.create_index('idx_wsj_status', ['status'], unique=False)
        batch_op.create_index('idx_wsj_status_started', ['status', 'started_at'], unique=False)

    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    with op.batch_alter_table('weather_scoring_jobs', schema=None) as batch_op:
        batch_op.drop_index('idx_wsj_status_started')
        batch_op.drop_index('idx_wsj_status')
        batch_op.drop_index('idx_wsj_score_type')
        batch_op.drop_index('idx_wsj_run_id')
        batch_op.drop_index('idx_wsj_created_at')

    op.drop_table('weather_scoring_jobs')
    # ### end Alembic commands ###
